---
phase: 03-sarah-chat-bot
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/gemini/client.ts
  - src/lib/gemini/types.ts
  - src/lib/sarah/prompts.ts
  - .env.local
autonomous: true

user_setup:
  - service: google-ai
    why: "Gemini 2.5 Flash API for Sarah's conversational AI"
    env_vars:
      - name: GEMINI_API_KEY
        source: "Google AI Studio -> Get API key (https://aistudio.google.com/apikey)"

must_haves:
  truths:
    - "Gemini 2.5 Flash API responds to test prompts"
    - "Sarah persona prompt produces warm, Indonesian-first responses"
    - "Structured output schema extracts 5 qualification fields"
  artifacts:
    - path: "src/lib/gemini/client.ts"
      provides: "Gemini API wrapper with chat sessions"
      exports: ["GeminiClient", "createChatSession"]
    - path: "src/lib/gemini/types.ts"
      provides: "TypeScript interfaces for Gemini responses and qualification data"
      exports: ["QualificationData", "GeminiChatMessage", "SarahState"]
    - path: "src/lib/sarah/prompts.ts"
      provides: "Sarah persona system prompt and state-specific instructions"
      exports: ["SARAH_SYSTEM_PROMPT", "getStatePrompt", "EXTRACTION_SCHEMA"]
  key_links:
    - from: "src/lib/gemini/client.ts"
      to: "GEMINI_API_KEY"
      via: "process.env"
      pattern: "process\\.env\\.GEMINI_API_KEY"
---

<objective>
Set up Gemini 2.5 Flash integration and create Sarah's persona prompt with structured output schema.

Purpose: This plan establishes the AI foundation for Sarah - the Gemini client that will be called from Kapso workflows, along with the carefully crafted persona prompts that define Sarah's personality and data extraction behavior.

Output:
- Working Gemini client with chat session support
- Sarah's system prompt (warm, Indonesian-first, 140 char limit)
- Structured output schema for 5-field extraction
- TypeScript types for conversation state
</objective>

<execution_context>
@/home/jfransisco/.claude/get-shit-done/workflows/execute-plan.md
@/home/jfransisco/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-sarah-chat-bot/03-CONTEXT.md
@business_21/03_bots/sarah-persona-and-flow.md
@business_21/03_bots/sarah-detailed-flow.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Gemini client with chat sessions</name>
  <files>
    src/lib/gemini/client.ts
    src/lib/gemini/types.ts
  </files>
  <action>
Install @google/generative-ai package. Create Gemini client wrapper:

1. **src/lib/gemini/types.ts** - TypeScript interfaces:
   - `QualificationData` - 5 fields: name, business_type, team_size, pain_points (string[]), goals
   - `SarahState` - Literal type: 'greeting' | 'qualifying' | 'scoring' | 'handoff' | 'completed'
   - `GeminiChatMessage` - role: 'user' | 'model', content: string
   - `SarahResponse` - response text + optional extracted data + next state suggestion

2. **src/lib/gemini/client.ts** - Gemini wrapper:
   - `GeminiClient` class with constructor taking API key
   - `createChatSession(history: GeminiChatMessage[])` - Creates multi-turn chat session
   - `generateWithSchema<T>(prompt: string, schema: object)` - Structured JSON output
   - `detectLanguage(message: string)` - Returns 'id' | 'en' based on patterns from sarah-detailed-flow.md

Use `gemini-2.5-flash` model. Handle API key from process.env.GEMINI_API_KEY.

Do NOT use the Vertex AI SDK - use the simpler Google AI SDK (@google/generative-ai).
  </action>
  <verify>
Run `npm run build` - no TypeScript errors
Create a test script that imports GeminiClient and calls generateWithSchema with a simple prompt
  </verify>
  <done>
Gemini client exists with chat sessions and structured output support, TypeScript types defined, imports work
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Sarah persona prompts and extraction schema</name>
  <files>src/lib/sarah/prompts.ts</files>
  <action>
Create Sarah's AI prompts based on persona documents:

1. **SARAH_SYSTEM_PROMPT** - Core persona (include in every Gemini call):
   - Indonesian by default (casual: Halo, Hai, Sip, Sama-sama, Kakak)
   - Under 140 characters per message (WhatsApp best practice)
   - 1-2 emoji max per message (sparingly)
   - Warm, helpful, not pushy - like a friendly intern
   - Never give specific prices - redirect to consultant
   - Show empathy: "Wah paham banget..." "Betul tuh..."
   - Time-based greetings: Selamat pagi/siang/sore/malam
   - Auto-switch to English if user messages in English

2. **getStatePrompt(state: SarahState)** - State-specific instructions:
   - `greeting`: Welcome, ask ONE open question about business
   - `qualifying`: Ask for missing field, ONE question per message, wait for response
   - `scoring`: If warm lead, continue conversation, answer questions helpfully
   - `handoff`: Transition message to consultant
   - `completed`: Closing message for cold leads

3. **EXTRACTION_SCHEMA** - JSON schema for Gemini structured output:
   ```typescript
   {
     type: "object",
     properties: {
       name: { type: "string", nullable: true },
       business_type: { type: "string", nullable: true },
       team_size: { type: "integer", nullable: true },
       pain_points: { type: "array", items: { type: "string" }, nullable: true },
       goals: { type: "string", nullable: true },
     },
     required: [] // All optional for partial extraction
   }
   ```

4. **Question templates** (Indonesian + English variants):
   - Name: "Boleh tau nama kakak siapa?" / "May I know your name?"
   - Business: "Bisnisnya di bidang apa ya kak?" / "What kind of business do you run?"
   - Team size: "Kalau handle chat/CS, tim ada berapa orang?" / "How many people handle customer chats?"
   - Pain points: "Ada challenge yang sering ketemu?" / "Any challenges you often face?"
   - Goals: "Harapannya apa pakai my21staff?" / "What are you hoping to achieve?"
  </action>
  <verify>
Run `npm run build` - no TypeScript errors
Import SARAH_SYSTEM_PROMPT and verify it's under 2000 chars (reasonable system prompt size)
  </verify>
  <done>
Sarah's persona prompt captures the warm, Indonesian-first personality with 140-char message limit
Extraction schema ready for structured Gemini output
State-specific prompts guide conversation flow
  </done>
</task>

<task type="auto">
  <name>Task 3: Add GEMINI_API_KEY to env and verify API connection</name>
  <files>.env.local</files>
  <action>
1. Add placeholder to .env.local:
   ```
   # Gemini API - Google AI Studio
   GEMINI_API_KEY=your-api-key-here
   ```

2. Create a quick verification script (don't commit, just for testing):
   - Import GeminiClient
   - Call a simple test prompt: "Say hello in Indonesian"
   - Verify response comes back

3. Update .env.example if it exists to include GEMINI_API_KEY placeholder

If API key is not set, the client should throw a clear error: "GEMINI_API_KEY not configured"
  </action>
  <verify>
Check .env.local has GEMINI_API_KEY line
If user has API key set, test call returns response
If API key missing, client throws informative error
  </verify>
  <done>
GEMINI_API_KEY environment variable documented and checked
Gemini API connection verifiable with test call
  </done>
</task>

</tasks>

<verification>
- [ ] `npm install @google/generative-ai` completed
- [ ] `npm run build` passes with no errors
- [ ] GeminiClient can be imported from src/lib/gemini/client.ts
- [ ] SARAH_SYSTEM_PROMPT is defined and captures persona
- [ ] EXTRACTION_SCHEMA matches QualificationData interface
- [ ] .env.local has GEMINI_API_KEY placeholder
</verification>

<success_criteria>
1. Gemini 2.5 Flash client wrapper exists with chat session support
2. Sarah's persona prompt is comprehensive and matches personality docs
3. Structured output schema enables 5-field extraction
4. TypeScript types are defined for all Sarah-related data structures
5. Environment variable setup is documented
</success_criteria>

<output>
After completion, create `.planning/phases/03-sarah-chat-bot/03-01-SUMMARY.md`
</output>
